{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "expired-membrane",
   "metadata": {},
   "source": [
    "# 1) Hinge Loss "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dense-activation",
   "metadata": {},
   "source": [
    "## a) Hinge Loss on One Data Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subtle-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raising-cornell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_single(feature_vector, label, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the hinge loss on a single data point given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing the given data point.\n",
    "        label - A real valued number, the correct classification of the data\n",
    "            point.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given data point and parameters.\n",
    "    \"\"\"\n",
    "    h = (np.dot(theta, feature_vector)) + theta_0\n",
    "    z = np.dot(label, h)\n",
    "    \n",
    "    if z >= 1:\n",
    "        hLoss = 0\n",
    "    else:\n",
    "        hLoss = 1 - z\n",
    "    \n",
    "    return hLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "mounted-corporation",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([1, 2])\n",
    "label, theta, theta_0 = 1, np.array([-1, 1]), -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "electric-encounter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss_single(feature_vector, label, theta, theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-relevance",
   "metadata": {},
   "source": [
    "## b) Hinge Loss on Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "determined-origin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss_full(feature_matrix, labels, theta, theta_0):\n",
    "    \"\"\"\n",
    "    Finds the total hinge loss on a set of data given specific classification\n",
    "    parameters.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        theta - A numpy array describing the linear classifier.\n",
    "        theta_0 - A real valued number representing the offset parameter.\n",
    "\n",
    "\n",
    "    Returns: A real number representing the hinge loss associated with the\n",
    "    given dataset and parameters. This number should be the average hinge\n",
    "    loss across all of the points in the feature matrix.\n",
    "    \"\"\"\n",
    "    h_loss = 0\n",
    "    for i in range(len(labels)): \n",
    "        h_loss = h_loss + hinge_loss_single(feature_matrix[i], labels[i], theta, theta_0)\n",
    "    h_loss = h_loss / len(labels)\n",
    "    return h_loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "binding-lover",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([[1, 2], [1, 2]])\n",
    "label, theta, theta_0 = np.array([1, 1]), np.array([-1, 1]), -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "prime-rates",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19999999999999996"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hinge_loss_full(feature_vector, label, theta, theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "differential-tunnel",
   "metadata": {},
   "source": [
    "# 2) Perceptron Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "labeled-affair",
   "metadata": {},
   "source": [
    "## a) Perceptron Single Step Update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "unnecessary-minister",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the perceptron algorithm.\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        current_theta - The current theta being used by the perceptron\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the perceptron\n",
    "            algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    # first check\n",
    "    ch = np.dot(label, np.dot(current_theta, feature_vector) + current_theta_0)\n",
    "    \n",
    "    if ch > 0:\n",
    "        theta = current_theta\n",
    "        theta_0 = current_theta_0\n",
    "    else:\n",
    "        theta = current_theta + (label * feature_vector)\n",
    "        theta_0 = current_theta_0 + label\n",
    "    \n",
    "    new_par = (theta, theta_0)\n",
    "    return new_par"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "hired-royalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([1, 2])\n",
    "label, theta, theta_0 = 1, np.array([-1, 1]), -1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "otherwise-charleston",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 3]), -0.5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per =perceptron_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        theta,\n",
    "        theta_0)\n",
    "per"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beautiful-triple",
   "metadata": {},
   "source": [
    "## b) Full Perceptron Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floating-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "def get_order(n_samples):\n",
    "    try:\n",
    "        with open(str(n_samples) + '.txt') as fp:\n",
    "            line = fp.readline()\n",
    "            return list(map(int, line.split(',')))\n",
    "    except FileNotFoundError:\n",
    "        random.seed(1)\n",
    "        indicies = list(range(n_samples))\n",
    "        random.shuffle(indicies)\n",
    "        return indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "diverse-disabled",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 9, 7, 5, 3, 0, 4, 1, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_order(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "saved-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the full perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta, the linear classification parameter, after T iterations through the\n",
    "    feature matrix and the second element is a real number with the value of\n",
    "    theta_0, the offset classification parameter, after T iterations through\n",
    "    the feature matrix.\n",
    "    \"\"\"\n",
    "    theta = np.zeros(feature_matrix.shape[1])\n",
    "    theta_0 = 0\n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            perc = perceptron_single_step_update(feature_matrix[i,:], \n",
    "                                                 labels[i],\n",
    "                                                 theta, theta_0)\n",
    "    return perc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "choice-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "weighted-chrome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_perc = perceptron(feature_matrix, labels, T)\n",
    "f_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-colleague",
   "metadata": {},
   "source": [
    "## c) Average Perceptron Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "european-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_perceptron(feature_matrix, labels, T):\n",
    "    \"\"\"\n",
    "    Runs the average perceptron algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    NOTE: Iterate the data matrix by the orders returned by get_order(feature_matrix.shape[0])\n",
    "\n",
    "\n",
    "    Args:\n",
    "        feature_matrix -  A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the perceptron algorithm\n",
    "            should iterate through the feature matrix.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the average theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the average theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "\n",
    "    Hint: It is difficult to keep a running average; however, it is simple to\n",
    "    find a sum and divide.\n",
    "    \"\"\"\n",
    "    theta = np.zeros(feature_matrix.shape[1])\n",
    "    theta_0 = 0.0\n",
    "    \n",
    "    # Keep track of the sum through the loops\n",
    "    theta_sum = np.zeros(feature_matrix.shape[1])\n",
    "    theta_0_sum = 0.0\n",
    "    \n",
    "    n = feature_matrix.shape[0]     # No of examples\n",
    "    \n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            theta, theta_0 = \\\n",
    "            perceptron_single_step_update(feature_matrix[i,:], labels[i], \\\n",
    "                                          theta, theta_0)\n",
    "            \n",
    "            theta_sum = theta_sum + theta\n",
    "            theta_0_sum = theta_0_sum + theta_0\n",
    "            \n",
    "    theta_avg = (1/(n*T))*theta_sum\n",
    "    theta_0_avg = (1/(n*T))*theta_0_sum\n",
    "    \n",
    "    return (theta_avg, theta_0_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "antique-functionality",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "indie-player",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 1.0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_perc = average_perceptron(feature_matrix, labels, T)\n",
    "f_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-contest",
   "metadata": {},
   "source": [
    "# 3) Pegasos Algorithm "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-curtis",
   "metadata": {},
   "source": [
    "## a) Pegasos Single Step Update "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strategic-squad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos_single_step_update(\n",
    "        feature_vector,\n",
    "        label,\n",
    "        L,\n",
    "        eta,\n",
    "        current_theta,\n",
    "        current_theta_0):\n",
    "    \"\"\"\n",
    "    Properly updates the classification parameter, theta and theta_0, on a\n",
    "    single step of the Pegasos algorithm\n",
    "\n",
    "    Args:\n",
    "        feature_vector - A numpy array describing a single data point.\n",
    "        label - The correct classification of the feature vector.\n",
    "        L - The lamba value being used to update the parameters.\n",
    "        eta - Learning rate to update parameters.\n",
    "        current_theta - The current theta being used by the Pegasos\n",
    "            algorithm before this update.\n",
    "        current_theta_0 - The current theta_0 being used by the\n",
    "            Pegasos algorithm before this update.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    theta after the current update has completed and the second element is a\n",
    "    real valued number with the value of theta_0 after the current updated has\n",
    "    completed.\n",
    "    \"\"\"\n",
    "    ch = float(label*(current_theta.dot(feature_vector) + current_theta_0))\n",
    "    \n",
    "    if ch <= 1.0:\n",
    "        current_theta = (1-eta*L)*current_theta + eta*label*feature_vector\n",
    "        current_theta_0 = current_theta_0 + eta*label\n",
    "    else:\n",
    "        current_theta = (1-eta*L)*current_theta\n",
    "        \n",
    "    return (current_theta, current_theta_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "harmful-hormone",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector = np.array([1, 2])\n",
    "label, theta, theta_0 = 1, np.array([-1, 1]), -1.5\n",
    "L = 0.2\n",
    "eta = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broadband-daily",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.88,  1.18]), -1.4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pegasos_single_step_update(\n",
    "        feature_vector,label,\n",
    "        L,eta,theta,theta_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "altered-mozambique",
   "metadata": {},
   "source": [
    "## b) Full Pegasos Algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "minus-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pegasos(feature_matrix, labels, T, L):\n",
    "    \"\"\"\n",
    "    Runs the Pegasos algorithm on a given set of data. Runs T\n",
    "    iterations through the data set, there is no need to worry about\n",
    "    stopping early.\n",
    "\n",
    "    For each update, set learning rate = 1/sqrt(t),\n",
    "    where t is a counter for the number of updates performed so far (between 1\n",
    "    and nT inclusive).\n",
    "\n",
    "    NOTE: Please use the previously implemented functions when applicable.\n",
    "    Do not copy paste code from previous parts.\n",
    "\n",
    "    Args:\n",
    "        feature_matrix - A numpy matrix describing the given data. Each row\n",
    "            represents a single data point.\n",
    "        labels - A numpy array where the kth element of the array is the\n",
    "            correct classification of the kth row of the feature matrix.\n",
    "        T - An integer indicating how many times the algorithm\n",
    "            should iterate through the feature matrix.\n",
    "        L - The lamba value being used to update the Pegasos\n",
    "            algorithm parameters.\n",
    "\n",
    "    Returns: A tuple where the first element is a numpy array with the value of\n",
    "    the theta, the linear classification parameter, found after T\n",
    "    iterations through the feature matrix and the second element is a real\n",
    "    number with the value of the theta_0, the offset classification\n",
    "    parameter, found after T iterations through the feature matrix.\n",
    "    \"\"\"\n",
    "    # Counter\n",
    "    c = 1\n",
    "    \n",
    "    # Initialize theta and theta0\n",
    "    current_theta = np.zeros(feature_matrix.shape[1])\n",
    "    current_theta_0 = 0.0\n",
    "    \n",
    "    for t in range(T):\n",
    "        for i in get_order(feature_matrix.shape[0]):\n",
    "            eta_t = 1/np.sqrt(c)  # Update eta every iteration\n",
    "            c += 1 # Update counter\n",
    "            \n",
    "            # Run pegasos algorithm to get theta and theta0\n",
    "            current_theta, current_theta_0 = pegasos_single_step_update(feature_matrix[i,:], \\\n",
    "             labels[i], L, eta_t, current_theta, current_theta_0)\n",
    "            \n",
    "    return (current_theta, current_theta_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "composite-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = np.array([[1, 2]])\n",
    "labels = np.array([1])\n",
    "T = 1\n",
    "L = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "standing-three",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2.]), 1.0)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pegasos(feature_matrix, labels, T, L)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statistical-curtis",
   "metadata": {},
   "source": [
    "# Comparing Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "devoted-interface",
   "metadata": {},
   "source": [
    "## Load Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "finnish-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "manufactured-armor",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path_data, extras=False):\n",
    "    \"\"\"\n",
    "    Returns a list of dict with keys:\n",
    "    * sentiment: +1 or -1 if the review was positive or negative, respectively\n",
    "    * text: the text of the review\n",
    "\n",
    "    Additionally, if the `extras` argument is True, each dict will also include the\n",
    "    following information:\n",
    "    * productId: a string that uniquely identifies each product\n",
    "    * userId: a string that uniquely identifies each user\n",
    "    * summary: the title of the review\n",
    "    * helpfulY: the number of users who thought this review was helpful\n",
    "    * helpfulN: the number of users who thought this review was NOT helpful\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    basic_fields = {'sentiment', 'text'}\n",
    "    numeric_fields = {'sentiment', 'helpfulY', 'helpfulN'}\n",
    "\n",
    "    data = []\n",
    "\n",
    "    f_data = open(path_data, encoding=\"latin1\")\n",
    "\n",
    "    for datum in csv.DictReader(f_data, delimiter='\\t'):\n",
    "        for field in list(datum.keys()):\n",
    "            if not extras and field not in basic_fields:\n",
    "                del datum[field]\n",
    "            elif field in numeric_fields and datum[field]:\n",
    "                datum[field] = int(datum[field])\n",
    "\n",
    "        data.append(datum)\n",
    "\n",
    "    f_data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "interracial-dakota",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'sentiment_analysis\\reviews_train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-922fd57e1d05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"sentiment_analysis\\reviews_train.tsv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mval_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment_analysis/reviews_val.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sentiment_analysis/reviews_test.tsv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtrain_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-44-e522c1a865e3>\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path_data, extras)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mf_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"latin1\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mdatum\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDictReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'sentiment_analysis\\reviews_train.tsv'"
     ]
    }
   ],
   "source": [
    "train_data = load_data(\"sentiment_analysis\\reviews_train.tsv\")\n",
    "val_data = load_data('sentiment_analysis/reviews_val.tsv')\n",
    "test_data = load_data('sentiment_analysis/reviews_test.tsv')\n",
    "\n",
    "train_texts, train_labels = zip(*((sample['text'], sample['sentiment']) for sample in train_data))\n",
    "val_texts, val_labels = zip(*((sample['text'], sample['sentiment']) for sample in val_data))\n",
    "test_texts, test_labels = zip(*((sample['text'], sample['sentiment']) for sample in test_data))\n",
    "\n",
    "dictionary = p1.bag_of_words(train_texts)\n",
    "\n",
    "train_bow_features = p1.extract_bow_feature_vectors(train_texts, dictionary)\n",
    "val_bow_features = p1.extract_bow_feature_vectors(val_texts, dictionary)\n",
    "test_bow_features = p1.extract_bow_feature_vectors(test_texts, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "awful-drill",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-daisy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6.86x",
   "language": "python",
   "name": "6.86x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
